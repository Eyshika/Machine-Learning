import dlib
import cv2
from matplotlib import pyplot as plt
import numpy as np
from skimage import io
import argparse
from collections import defaultdict
from keras_vggface.vggface import VGGFace
from keras.engine import Model
from keras.layers import Input
import imutils
from sklearn import svm
import numpy as np
from cv2 import VideoWriter, VideoWriter_fourcc

from imutils import face_utils
#face landmark

def rect_to_bb(rect):
      #take a boundary predicted by dlib
      #and convert it to the format (x,y,w,h) as we
      #would normally do with OpenCV
    x=rect.left()
    y=rect.top()
    w=rect.right()-x
    h=rect.bottom()-y
      
      #return a tuple of (x,y,w,h)
    return (x,y,w,h)

def shape_to_np(shape, dtype="int"):
      #initialize the list of x,y coordinates
    coords= np.zeros((68,2), dtype=dtype)
      #loop over the 68 facial landmarks and convertthem
      # to a 2-tuple of x,y cordinates
    for i in range(0,68):
        coords[i]=(shape.part(i).x, shape.part(i).y)
      #return list of x,y coordinates
    return coords

ap=argparse.ArgumentParser()  
path_shape_predictor="shape_predictor_68_face_landmarks.dat"   
detector=dlib.get_frontal_face_detector()
predictor=dlib.shape_predictor(path_shape_predictor)

#importing video and extracting frames

vidcap = cv2.VideoCapture('video2.mp4')
success,image = vidcap.read()

count = 0
cv2.imwrite("frames2/frame%d.jpg" % count, image)
success = True
count +=1
while success:
    success,image = vidcap.read()
    #print('Read a new frame: ', success)
    cv2.imwrite("frames2/frame%d.jpg" % count, image)     # save frame as JPEG file
    count += 1
    
imgs = defaultdict(list)
names = ['donald_trump','jimmy_fallon']
#im0 = cv2.imread("donald_trump/1.jpg")
#plt.imshow(im0)
#plt.show()
r=[27,27]
for j,name in enumerate(names):
    for i in range(r[j]):
        img = cv2.imread("{}/{}.jpg".format(name,i))
        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)
        gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
        #faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        #face_imgs = []
        """
        print(i)
        try:
            print(faces.shape)
        except:
            print("shit")
            """
        rects=detector(gray,1)
        for (i,rect) in enumerate(rects):
            #determine the facial landmarks for the face region, then
            #convert the facial landmark x,y coordinate to a NumPy array
    
            shape1=predictor(gray, rect)
            shape1=face_utils.shape_to_np(shape1)

            #convert dlib's rectangle to a OpenCv style bounding box i.e. x,y,w,h then draw the face bounding box
            (x,y,w,h)=face_utils.rect_to_bb(rect)
            face = img[y:y+h,x:x+w]
            face = cv2.resize(face,(224,224),interpolation=cv2.INTER_AREA)
            imgs[name].append(face)
            #plt.imshow(face)
            #plt.show()
            
nums = {}
for name in names:
    nums[name]=len(imgs[name])
    print(nums[name])

vgg_feat = VGGFace(include_top=False,input_shape=(224,224,3),pooling='avg')
vgg_feat.output_shape

tensors = {}
for name in names:
    tensors[name] = np.reshape(imgs[name][0],(1,224,224,3))
    for i in range(1,nums[name]-1):
        tensors[name] = np.append(tensors[name],np.reshape(imgs[name][i],(1,224,224,3)),axis=0)

print(tensors['donald_trump'].shape)

preds = {}

for name in names:
    preds[name] = vgg_feat.predict(tensors[name])
print(preds['donald_trump'].shape)

samples = preds[names[0]]
samples = np.append(samples,preds[names[1]],axis=0)

print(samples.shape)

labels = np.array([0])
for i in range(1,nums['donald_trump']-1):
    labels = np.append(labels,[0],axis=0)
for i in range(0,nums['jimmy_fallon']-1):
    labels = np.append(labels,[1],axis=0)
print(labels[10])
print(labels.shape)

clf = svm.SVC(probability=True)
clf.fit(samples,labels)
clf.predict(samples)

for i in range(0,210):
    Image = cv2.imread("frames2/frame{}.jpg".format(i))
    #path_image="fallon_trump.png"  
    Image = cv2.cvtColor(Image,cv2.COLOR_BGR2RGB)
    #Image=imutils.resize(hogimage, width=500)
    gray=cv2.cvtColor(Image, cv2.COLOR_BGR2GRAY)

    rects=detector(gray,1)

    face_imgs = []
    coords = [];
    for (j,rect) in enumerate(rects):
        #determine the facial landmarks for the face region, then
        #convert the facial landmark x,y coordinate to a NumPy array
    
        shape1=predictor(gray, rect)
        shape1=face_utils.shape_to_np(shape1)

        #convert dlib's rectangle to a OpenCv style bounding box i.e. x,y,w,h then draw the face bounding box
        (x,y,w,h)=face_utils.rect_to_bb(rect)
        if (w > 50):
            coords.append([x,y,w,h])
            face_imgs.append(Image[y:y+h,x:x+w])
        #cv2.rectangle(Image, (x,y),(x+w, y+h), (0, 255,0),2)
    
    labs = [];
    for face in face_imgs:
        #plt.imshow(face)
        face = cv2.resize(face,(224, 224), interpolation = cv2.INTER_AREA)
        face = np.reshape(face,(1,224,224,3))
        p = vgg_feat.predict(face)
        labs.append(clf.predict(p))
        #plt.show()
        #print(clf.predict(p))
    for j,(x,y,w,h) in enumerate(coords):
        cv2.rectangle(Image, (x,y),(x+w,y+h),(0,255,0),2)
        print(labs[j][0])
        cv2.putText(Image, names[labs[j][0]], (x, y+h+25), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2, cv2.LINE_AA)
        
    plt.imshow(Image)
    plt.show()
    Image = cv2.cvtColor(Image,cv2.COLOR_RGB2BGR)
    cv2.imwrite("out2/frame{}.jpg".format(i),Image)
    
    fourcc = VideoWriter_fourcc(*'XVID')
vid = None
size = None
images = []
for i in range(0,210):
    images.append("out2/frame{}.jpg".format(i))
for image in images:
    img = cv2.imread(image)
    if vid is None:
        if size is None:
            size = img.shape[1], img.shape[0]
        vid = VideoWriter("outvid.avi", fourcc, float(24),size,True)
    vid.write(img)
vid.release()
